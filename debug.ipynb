{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from typing import Dict, Any\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from fire import Fire\n",
    "from omegaconf import OmegaConf\n",
    "from pytorch_toolbelt.utils.distributed import is_main_process\n",
    "from pytorch_toolbelt.utils import fs\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xview3 import *\n",
    "from xview3.centernet.visualization import create_false_color_composite, vis_detections_opencv\n",
    "from xview3.constants import PIX_TO_M\n",
    "from xview3.inference import (\n",
    "    predict_multilabel_scenes,\n",
    ")\n",
    "\n",
    "from submit_multilabel_ensemble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up rank=0 world_size=2 backend='nccl'\n",
      "master_addr='localhost' master_port='48857'\n",
      "setting up rank=1 world_size=2 backend='nccl'\n",
      "master_addr='localhost' master_port='48857'\n",
      "rank=0 init complete\n",
      "rank=1 init complete\n",
      "Initialized distributed inference 0 2\n"
     ]
    }
   ],
   "source": [
    "configs = 'configs/inference/light2.yaml'\n",
    "world_size = 1\n",
    "master_addr = 'localhost'\n",
    "master_port = find_free_port()\n",
    "# os.environ['MASTER_ADDR'] = master_addr\n",
    "# os.environ['MASTER_PORT'] = master_port\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "data_dir=os.environ.get(\"XVIEW3_DIR\", \"g:/xview3\" if os.name == \"nt\" else \"/home/bloodaxe/data/xview3\")\n",
    "local_rank=int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "world_size=2 #int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "\n",
    "if world_size > 1:\n",
    "        # torch.distributed.init_process_group(backend=\"gloo\",world_size =2,rank = 0)\n",
    "        # mp.spawn(setup_process,args=(master_addr,master_port,world_size), nprocs = 1)\n",
    "        mp.spawn(setup_process,args=(master_addr,master_port,world_size), nprocs = world_size)\n",
    "        # torch.cuda.set_device(local_rank)\n",
    "        print(\"Initialized distributed inference\", local_rank, world_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying sigmoid activation to ['CENTERNET_OUTPUT_OBJECTNESS_MAP', 'CENTERNET_OUTPUT_VESSEL_MAP', 'CENTERNET_OUTPUT_FISHING_MAP'] after each model 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m normalization_op \u001b[38;5;241m=\u001b[39m build_normalization(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_data\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalization\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m channels \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_data\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m _, _, eval_df, shore_root \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_val_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_folds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m test_scenes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data\u001b[38;5;241m.\u001b[39mget_test_scenes())\n\u001b[1;32m     21\u001b[0m channels_last \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/smartSatCRC/xView3-The-First-Place-Solution/xview3/dataset/data_module.py:175\u001b[0m, in \u001b[0;36mXView3DataModule.train_val_split\u001b[0;34m(self, splitter, fold, num_folds)\u001b[0m\n\u001b[1;32m    172\u001b[0m     splitter_name \u001b[38;5;241m=\u001b[39m splitter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    173\u001b[0m     splitter_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((k, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m splitter\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m splitter_cls: DatasetSplitter \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m: PrecomputedSplitter,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtiny\u001b[39m\u001b[38;5;124m\"\u001b[39m: TinyDatasetSplitter,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_only\u001b[39m\u001b[38;5;124m\"\u001b[39m: ValidationOnlySplitter,\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_only_with_holdout\u001b[39m\u001b[38;5;124m\"\u001b[39m: ValidationOnlyWithHoldoutSplitter,\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m: FullDatasetWithHoldoutSplitter,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: EvalPublicDatasetSplitter,\n\u001b[1;32m    182\u001b[0m }[splitter_name](data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msplitter_params)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m splitter_cls\u001b[38;5;241m.\u001b[39mtrain_test_split(fold\u001b[38;5;241m=\u001b[39mfold, num_folds\u001b[38;5;241m=\u001b[39mnum_folds)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test'"
     ]
    }
   ],
   "source": [
    "data_dir='/media/ibrahm/SSD2TB870EV/xViewSARData/xView3dataForWinner'\n",
    "config = OmegaConf.load(configs)\n",
    "data = XView3DataModule(data_dir)\n",
    "\n",
    "model, checkpoints, box_coder = ensemble_from_config(config)\n",
    "\n",
    "checkpoint = checkpoints[0]\n",
    "normalization_op = build_normalization(checkpoint[\"checkpoint_data\"][\"config\"][\"normalization\"])\n",
    "channels = checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"channels\"]\n",
    "\n",
    "_, _, eval_df, shore_root = data.train_val_split(\n",
    "    splitter=\"test\",\n",
    "    fold=checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"fold\"],\n",
    "    num_folds=checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"num_folds\"],\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "test_scenes = np.array(data.get_test_scenes())\n",
    "\n",
    "channels_last = config[\"inference\"][\"channels_last\"]\n",
    "tile_size = config[\"inference\"][\"tile_size\"]\n",
    "tile_step = config[\"inference\"][\"tile_step\"]\n",
    "tta_mode = config[\"ensemble\"][\"tta\"]\n",
    "\n",
    "submission_dir = config[\"submission_dir\"]\n",
    "os.makedirs(submission_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"splitter\"])\n",
    "print(checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"fold\"])\n",
    "print(checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"num_folds\"])\n",
    "print(np.array(data.get_test_scenes()))\n",
    "# print(holdout_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('scene: ',test_scenes)\n",
    "print('last channels: ',channels_last) \n",
    "print('tile size: ',tile_size) \n",
    "print('tile step: ',tile_step) \n",
    "print('tta mode: ',tta_mode) \n",
    "print('sub directory: ',submission_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if config[\"inference\"][\"use_traced_model\"]:\n",
    "    traced_model_path = os.path.join(submission_dir, \"traced_ensemble.jit\")\n",
    "    if os.path.exists(traced_model_path):\n",
    "        model = torch.jit.load(traced_model_path)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            if channels_last:\n",
    "                model = model.to(memory_format=torch.channels_last)\n",
    "                print(\"Using channels last format\")\n",
    "\n",
    "            model = torch.jit.trace(\n",
    "                model,\n",
    "                example_inputs=torch.randn(1, len(channels), tile_size, tile_size).cuda(),\n",
    "                strict=False,\n",
    "            )\n",
    "            if is_main_process():\n",
    "                torch.jit.save(model, traced_model_path)\n",
    "\n",
    "del checkpoints\n",
    "gc.collect()\n",
    "\n",
    "prefix = \"test_\"\n",
    "suffix = f\"_step_{tile_step}_tta_{tta_mode}\"\n",
    "\n",
    "test_predictions_dir = os.path.join(submission_dir, f\"{prefix}{suffix}\")\n",
    "os.makedirs(test_predictions_dir, exist_ok=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xview3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
