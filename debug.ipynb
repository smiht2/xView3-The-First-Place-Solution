{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibrahm/miniconda3/envs/xview3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from typing import Dict, Any\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from fire import Fire\n",
    "from omegaconf import OmegaConf\n",
    "from pytorch_toolbelt.utils.distributed import is_main_process\n",
    "from pytorch_toolbelt.utils import fs\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xview3 import *\n",
    "from xview3.centernet.visualization import create_false_color_composite, vis_detections_opencv\n",
    "from xview3.constants import PIX_TO_M\n",
    "from xview3.inference import (\n",
    "    predict_multilabel_scenes,\n",
    ")\n",
    "\n",
    "from submit_multilabel_ensemble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up rank=0 world_size=2 backend='nccl'\n",
      "master_addr='localhost' master_port='38371'\n",
      "setting up rank=1 world_size=2 backend='nccl'\n",
      "master_addr='localhost' master_port='38371'\n",
      "rank=0 init complete\n",
      "rank=1 init complete\n",
      "Initialized distributed inference 0 2\n"
     ]
    }
   ],
   "source": [
    "configs = 'configs/inference/1128_b5_b4_vs2_fliplr.yaml'\n",
    "world_size = 1\n",
    "master_addr = 'localhost'\n",
    "master_port = find_free_port()\n",
    "# os.environ['MASTER_ADDR'] = master_addr\n",
    "# os.environ['MASTER_PORT'] = master_port\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "data_dir=os.environ.get(\"XVIEW3_DIR\", \"g:/xview3\" if os.name == \"nt\" else \"/home/bloodaxe/data/xview3\")\n",
    "local_rank=int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "world_size=2 #int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "\n",
    "if world_size > 1:\n",
    "        # torch.distributed.init_process_group(backend=\"gloo\",world_size =2,rank = 0)\n",
    "        # mp.spawn(setup_process,args=(master_addr,master_port,world_size), nprocs = 1)\n",
    "        mp.spawn(setup_process,args=(master_addr,master_port,world_size), nprocs = world_size)\n",
    "        # torch.cuda.set_device(local_rank)\n",
    "        print(\"Initialized distributed inference\", local_rank, world_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying sigmoid activation to ['CENTERNET_OUTPUT_OBJECTNESS_MAP', 'CENTERNET_OUTPUT_VESSEL_MAP', 'CENTERNET_OUTPUT_FISHING_MAP'] after each model 12\n",
      "Wrapping models with TTA fliplr\n"
     ]
    }
   ],
   "source": [
    "data_dir='/media/ibrahm/SSD2TB870EV/xViewSARData/xView3dataForWinner'\n",
    "config = OmegaConf.load(configs)\n",
    "data = XView3DataModule(data_dir)\n",
    "\n",
    "model, checkpoints, box_coder = ensemble_from_config(config)\n",
    "\n",
    "checkpoint = checkpoints[0]\n",
    "normalization_op = build_normalization(checkpoint[\"checkpoint_data\"][\"config\"][\"normalization\"])\n",
    "channels = checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"channels\"]\n",
    "\n",
    "    # _, _, holdout_df, shore_root = data.train_val_split(\n",
    "    #     splitter=checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"splitter\"],\n",
    "    #     fold=checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"fold\"],\n",
    "    #     num_folds=checkpoint[\"checkpoint_data\"][\"config\"][\"dataset\"][\"num_folds\"],\n",
    "    # )\n",
    "\n",
    "test_scenes = np.array(data.get_test_scenes())\n",
    "\n",
    "channels_last = config[\"inference\"][\"channels_last\"]\n",
    "tile_size = config[\"inference\"][\"tile_size\"]\n",
    "tile_step = config[\"inference\"][\"tile_step\"]\n",
    "tta_mode = config[\"ensemble\"][\"tta\"]\n",
    "\n",
    "submission_dir = config[\"submission_dir\"]\n",
    "os.makedirs(submission_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene:  ['/media/ibrahm/SSD2TB870EV/xViewSARData/xView3dataForWinner/test/05bc615a9b0e1159t'\n",
      " '/media/ibrahm/SSD2TB870EV/xViewSARData/xView3dataForWinner/test/72dba3e82f782f67t']\n",
      "last channels:  False\n",
      "tile size:  2048\n",
      "tile step:  1536\n",
      "tta mode:  fliplr\n",
      "sub directory:  submissions/1128_b5_b4_vs2_fliplr\n"
     ]
    }
   ],
   "source": [
    "print('scene: ',test_scenes)\n",
    "print('last channels: ',channels_last) \n",
    "print('tile size: ',tile_size) \n",
    "print('tile step: ',tile_step) \n",
    "print('tta mode: ',tta_mode) \n",
    "print('sub directory: ',submission_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if config[\"inference\"][\"use_traced_model\"]:\n",
    "    traced_model_path = os.path.join(submission_dir, \"traced_ensemble.jit\")\n",
    "    if os.path.exists(traced_model_path):\n",
    "        model = torch.jit.load(traced_model_path)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            if channels_last:\n",
    "                model = model.to(memory_format=torch.channels_last)\n",
    "                print(\"Using channels last format\")\n",
    "\n",
    "            model = torch.jit.trace(\n",
    "                model,\n",
    "                example_inputs=torch.randn(1, len(channels), tile_size, tile_size).cuda(),\n",
    "                strict=False,\n",
    "            )\n",
    "            if is_main_process():\n",
    "                torch.jit.save(model, traced_model_path)\n",
    "\n",
    "del checkpoints\n",
    "gc.collect()\n",
    "\n",
    "prefix = \"test_\"\n",
    "suffix = f\"_step_{tile_step}_tta_{tta_mode}\"\n",
    "\n",
    "test_predictions_dir = os.path.join(submission_dir, f\"{prefix}{suffix}\")\n",
    "os.makedirs(test_predictions_dir, exist_ok=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xview3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
